MPC (5-8p) [currently 3p]

-----------------------------------------------------------------------------------------------------------
* Introduction to control theory [1p] (1p)
* Model Predictive control [1p] (0.5p)
	- basic idea, explain the general idea of algorithm
	- algorithm
	- some explanations

* MPC problems [1.5p]
	- closed loop system define
	- costs
	- optimal value of cost
	- stabilizing mpc
	- economic mpc

* convection diffusion pde [1p] (1.5p)
	- intro
	- boundary condition
	- problem statement
	- solution methods

-----------------------------------------------------------------------------------------------------------


Model predictive control is a powerful optimization strategy for feedback control that involves using a system model to predict the control variables of a dynamic system. It is a very flexible procedue where if we have a system model as in fig. we run the forecasts of this model forward in time for different actuation strategies u and using MPC we can optimize over the control input u over a short time period to determine the next immediate control action. Once, the contorl action is applied in the first time step, MPC iteratively calculates the next control action for the new forecasted system state.
MPC has been used in industry for process control since 1980s. One main reason is that it can handle MIMO systems, where multiple input and output variables of a system are interdependent. Simple controller like PID, failt to optimally control such systems especially when there are many interdependent input/output variables. MPC can also handle constraints which is nothing but a limitation on choice of control parameters that resembles a real world scenario. For example, consider a control problem of keeping an autnomous car in the right lane, the constraints for speed could be, the speed cannot exceed the speed limit in that area and another could be, the car must maintain a certain safe distance from other cars. MPC can also incorporate future reference information into the control problem to improve controller performance. Despite these benefits, MPC does require a powerful and fast processor since it solves this optimization problem in an online manner at each timestep.

Now that we have established the general idea behind MPC, lets go into more details by first defining the problem being solved and then the MPC algorithm along with its important components. We will refer to the problem as defined in thesis: x that uses MPC for partial differential equation control. Consider a continuous-time control system,
\equation
where x which represents the state of system at time t and u the control action. Given an initial state x0, iteratively applying f leads to a number of different states known as state trajectories for example, for controls u, the state trajectories are x. A control problem for such a system could be to select the control actions that take the system to a desired behavior. Here, the desired behavior could either be to stabilize the system to a predefined state of to prevent the system from entering a certain region[]. In general the desired behavior of a system can be modelled by an optimal control problem which comes from optimal control theory where the main goal is to find a control for a dynamical system such that an objective function is optimized. The objective function (aka. cost function) is basically a mapping from state and action space to a one-dimensional numerical value and is given by J,
\equation
In the above cost function, l should be selected in such a way that it penalizes the deviation from target state. This results in the goal of finding the control sequence uU that minimizes this deviation. Hence, the optimal control problem becomes,One more important step to make this control problem more realistic is to apply constraints on the type of values for state and actions. As mentioned earlier, constraints are important for the system to resemble real world behavior. Here, lets say that the set of allowed state and actions are represented by X and U respectively and U is defined as follows,
\equation
The final optimal control problem then becomes,
\equation
Although this is a continuous time problem, MPC aka, receding horizon control, can solve such problems by operating over a finite horizon in time.


The basic idea behind MPC is to solve the optimal control problem for a finite number of steps NN. This results in the following control sequence.
\equation
Out of these control sequences, only the first value is used as the optimal action. There on, the optimal control is applied on the system and the system moves forward in time. Then, the optimization problem is solved again and the next best actions are chosen for this shifted horizon. This is an iterative process and is done indefinitely in an online manner. The following algorithm showcases these steps formally, as proposed in [].
Algorithm1
For each time instant k = 0, 1, ...
	i) Measure the current state x = x(t) of the system
	ii) Solve the optimal control problem in order to obtain the optimal control sequence
	iii) Apply the first element of un as a control to the system during the next sampling period
	iv) set k = k + 1, and repeat from beginning

approx 1 page pending
- Talk about stabilizing mpc vs economic mpc?
- talk about different classes of MPC problems? from
https://www.researchgate.net/publication/324748527_DIFFERENT_PROBLEM_CLASSES_AND_SOLUTION_TECHNIQUES_FOR_MODEL_PREDICTIVE_BUILDING_CONTROL







Example
In this section we discuss how to frame a convection diffusion equation control problem as an MPC problem. We discuss one of the two scenarios described in [] of bilinear optimal control problem, where control is applied using boundary control and controlled convection term in a 1D domain.

Convection-diffusion equation [3p]
	- problem statement
	- weak form

	- Solution
		- spatial discretization using Galerkin method
		- time discretization using implicit euler
		- finite dimensional optimal control problem

Convection diffusion equation models the change in physical elements like velocity, temperature in a physical dynamic system in the presence of convective and diffusive processes. Specifically in the problem disscussed here, this equation models the dispersion of temperature inside a room by conductive heat transfer (eg. radiatio) and convective transfer induced by velocity field (eg. air flow) [] and is given by,
\equation
\equation
\equation
where the domain (e.g. room) xxxx, T>0 are the number of time steps. uuu is the temperature at each point in xxx, D is the diffusion coefficient, v: xxxxxx is the velocity field and u0: xxxxxx is the initial temperature distribution. Here, the diffusion term is xxxxx and the convection term is xxxx. Note that the names of some quantities have been changed from what is originally mentioned in [] to keep the notation consistent with rest of the thesis.

As mentioned in section PDE, in order to solve any pde, the boundary conditions must be specified. In this scenario, the temperature inside the room is influenced by the outside temperature and so the boundary conditions are given by,
\equation
\equation
\equation
\equation
The boundaries conditions can be divided into two parts, TC and Tout, Tc is the one that can be controlled by setting the temperature inside the room by using some form of heating or cooling and Tout is the one that cannot be controlled but is given by the temperature outside the room. Also, for PDEs the two types of boundary conditions, dirichlet and neumann can be inforced by choosing the value of V appropriately. For example, if Vxxxx means setting the temperature at each point in the boundary to some value from function Dc and represents the Dirichlet boundary condition. While, V=0, represents the neumann boundary condition where the temperature at each point on the boundary is 0.

Using the above setting, the problem statement can be defined as follows, Control the temperature inside the room such that it lies within the lower and upper bounds uxx and uxx while minimizing the cost of control actions (e.g. total energy used).
This results in two control actions being performed one at the boundary and the other using the velocity field e.g. a ventilator/fan inside the room. The optimal control problem is then given by[],
\equation
\equation
\equation
\equation
\equation
\equation
\equation
\equation
\equation

Next, we briefly discuss the solution to this minimization problem. For detailed in-depth derivation of terms, we refer to the paper []. In short the approach used in the original paper is called first-discretize-then-optimize approach and involves five steps.
	i) From strong form to weak form
	ii) Spatial discretization by Galerkin method
	iii) time discretization by implicit euler method
	iv) discretization of cost function
	v) solving the discretized problem by finite element method
There are two types of solutions for a pde, strong form and weak form. Generally speaking, the strong form solution involves satisfying both dirichlet and neumann boundary conditions and thats makes it harder to calculate while the weak form solution invovles only satisfying the dirichlet boundary conditions. Generally speaking, the weak form involves integrating the equation after multiplying with weighted function to identify those terms in the equation whose derivatives can be balanced. The idea behind spatial discretization using Galerkin method is to represent the a function as linear combination of basis functions. This is equivalent to finite element method discussed in section PDE and involves subdividing the domain O into subsets Ki, e.g. by triangulation. Later polynomial trial functions are applied on each subset[]. This reduces the PDE into nonlinear ODEs.

































